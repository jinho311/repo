{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Assignment\n",
        "## 다음과 같은 CNN 모델을 작성해보자\n",
        "\n",
        "* Input\n",
        "  * Input type: torch.Tensor  \n",
        "  * Input shape: (?, 1, 28, 28)\n",
        "    * 여러장의, 흑백, 28x28 size의 이미지라고 가정하자\n",
        "* Layers  \n",
        "  * Layer 1\n",
        "    * Conv2d >> C: 32, Kernel size (필터 크기): 3, Stride: 1, Padding: 1  \n",
        "    * ReLu  \n",
        "    * MaxPool >> Kernel size: 2, Stride: 2\n",
        "    * 입-출력 (?, 1, 28, 28) >> (?, 32, 14, 14)\n",
        "  * Layer 2\n",
        "    * Conv2d >> C: 64, Kernel size (필터 크기): 3, Stride: 1, Padding: 1\n",
        "    * ReLU\n",
        "    * MaxPool >> Kernel size: 2, Stride: 2\n",
        "    * 입-출력 (?, 32, 14, 14) >> (?, 64, 7, 7)\n",
        "  * Layer 3\n",
        "    * Conv2d >> C: 128, Kernel size (필터 크기): 3, Stride: 1, Padding: 1\n",
        "    * ReLU\n",
        "    * MaxPool >> Kernel size: 2, Stride: 2, Padding: 1\n",
        "    * 입-출력 (?, 64, 7, 7) >> (?, 128, 4, 4)\n",
        "  * Layer 4\n",
        "    * Linear >> input: 4x4x128 output: 625\n",
        "    * ReLU\n",
        "    * Dropout\n",
        "    * 입-출력 (4x4x128) >> (625)\n",
        "  * Layer 5\n",
        "    * Linear >> input: 625 output: 10\n",
        "    * Softmax (pytorch의 Cross Entropy Loss 함수를 사용하는 것을 감안한다)"
      ],
      "metadata": {
        "id": "7WE2UVM14YXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP4Wp6N-UaPL"
      },
      "outputs": [],
      "source": [
        "# Pytorch, Dataset을 관리하는 torchvsion.datasets, 데이터셋을 변형하는 torchvision.transforms, 뉴럴 네트워크를 위한 nn 이 임포트 되었다.\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as opt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cuda라는 장치가 연산처리가 가능하면 Cuda를 사용한다. 이외에는 cpu로 연산을 처리한다.(Cuda=GPU)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility, 학습결과를 어느수준 일정하게 만들기 위하여 시드를 부여한다. Cuda를 사용하는 경우 Cuda에도 시드를 부여해줘야한다.\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "zeo5wSfi5ypw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN을 사용하기 위해 클래스를 정의한다.\n",
        "# Sequential 함수를 통해 여러 연속적인 동작을 하나의 Layer로 묶을 수 있다.\n",
        "# Conv2d는 2차원 모델을 convolution 하는 함수 (N은 배치사이즈,  커널 사이즈 = 필터 사이즈, stride, padding 지정가능)\n",
        "# ReLu는 다루지 않는다.\n",
        "# MaxPool2d는 2차원의 모델을 Max-Pooling하는 함수\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 Input shape=(?, 1, 28, 28)\n",
        "        #    Conv     -> (?, 32, 28, 28)\n",
        "        #    Pool     -> (?, 32, 14, 14)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 Input shape=(?, 32, 14, 14)\n",
        "        #    Conv      ->(?, 64, 14, 14)\n",
        "        #    Pool      ->(?, 64, 7, 7)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L3 Input shape=(?, 64, 7, 7)\n",
        "        #    Conv      ->(?, 128, 7, 7)\n",
        "        #    Pool      ->(?, 128, 4, 4) (padding 1)\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
        "        # L4 Linear 128x4x4 inputs -> 625 outputs\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(128*4*4, 625, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=0.2)  #Dropout이란 뉴럴네트워크의 경로 몇개를 버리면서 학습하는 것으로, overfitting을 방지하는 효과를 가진다.\n",
        "        )\n",
        "        # L5 Linear 625 inputs -> 10 outputs\n",
        "        self.layer5 = torch.nn.Linear(625, 10, bias=True)\n",
        "        # 자비에르 유니폼: Linear의 초깃값을 0이아닌 자비에르방식으로 설정.\n",
        "        torch.nn.init.xavier_uniform_(self.layer5.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC , Linear연산을 하기 전에 한줄 벡터로 변환하여 입력한다.\n",
        "        out = self.layer5(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "UhLx83i_MN8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}