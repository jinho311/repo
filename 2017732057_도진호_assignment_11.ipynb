{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Assignment\n",
        "## 다음 미완성 코드를 활용해 새로운 data를 학습해보자\n",
        "\n",
        "* Training data image\n",
        "  * Shape: (?, 3, 64, 128)\n",
        "    * 여러장의, RGB, 64x128 size의 이미지라고 가정하자\n",
        "* Test data image\n",
        "  * Shape: (?, 3, ?, ?)\n",
        "    * 여러장의, RGB, size를 알 수 없는 이미지라고 가정하자\n",
        "* Lables\n",
        "  * image의 class는 2가지 이다\n",
        "  * data folder의 구성을 참고하자\n",
        "* Data folder 위치\n",
        "  * 노트북 github의 data folder 2개를 적당한 위치에 카피해 사용한다"
      ],
      "metadata": {
        "id": "-PenUOCrFzn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nwm6LduFori",
        "outputId": "020b95da-0f61-4650-cffd-a9f5429314dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 임포트 및 GPU사용, colab에 mount, 시드 부여 등 학습 모델 외적으로 사용하는 코드들\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 지난 assignment에서 작성한 model을 활용한다. 바뀐 image의 size는 64x128이며, 흑백이 아닌 RGB 3개의 채널임에 유의한다.\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 Input shape=(?, 3, 64, 128)\n",
        "        #    Conv     -> (?, 32, 64, 128)\n",
        "        #    Pool     -> (?, 32, 32, 64)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 Input shape=(?, 32, 32, 64)\n",
        "        #    Conv      ->(?, 64, 32, 64)\n",
        "        #    Pool      ->(?, 64, 16, 32)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L3 Input shape=(?, 64, 16, 32)\n",
        "        #    Conv      ->(?, 128, 16, 32)\n",
        "        #    Pool      ->(?, 128, 8, 16)\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L4 Linear 128x8x16 inputs -> 625 outputs\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(128*8*16, 625, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=0.5))  #Dropout이란 뉴럴네트워크의 경로 몇개를 버리면서 학습하는 것으로, overfitting을 방지하는 효과를 가진다.\n",
        "        # L5 Linear 625 inputs -> 2 outputs\n",
        "        self.layer5 = torch.nn.Linear(625, 2, bias=True),\n",
        "        # 자비에르 유니폼: Linear의 초깃값을 0이아닌 자비에르방식으로 설정.\n",
        "        torch.nn.init.xavier_uniform_(self.layer5.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC , Linear연산을 하기 전에 한줄 벡터로 변환하여 입력한다.\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "aEsJ-sllGz93"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "learning_rate = 0.0005\n",
        "training_epochs = 10"
      ],
      "metadata": {
        "id": "fMffc7OJhSNZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contruct model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)   \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1xa3kSC7HIGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "3f9f5268-4db6-4eeb-9395-a44302bb4cfc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-68697a83a55b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# contruct model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# define cost/loss & optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-abbf1b27f92c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m625\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# 자비에르 유니폼: Linear의 초깃값을 0이아닌 자비에르방식으로 설정.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'weight'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "##### 직접 dataset을 만들어 학습할 때 자주 사용되는 함수이니 기능을 숙지한다\n",
        "##### pytorch 공식 홈페이지에서 관련 함수의 정보를 직접 찾아보는 것을 추천한다\n",
        "trans = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = dsets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/courses/AI_Appl/train_data', transform=trans)\n",
        "data_loader = DataLoader(dataset = train_data, batch_size = 8, shuffle = True)\n",
        "\n",
        "total_batch = len(data_loader)"
      ],
      "metadata": {
        "id": "PlEkJnbKHVRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 학습이 이루어지는 loop\n",
        "##### 지난 source code를 그대로 사용해도 되지만, 연습삼아 직접 작성해보자\n"
      ],
      "metadata": {
        "id": "qym3rGnjHXGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "##### 직접 dataset을 만들어 학습할 때 자주 사용되는 함수이니 기능을 숙지한다\n",
        "##### pytorch 공식 홈페이지에서 관련 함수의 정보를 직접 찾아보는 것을 추천한다\n",
        "trans=transforms.Compose([transforms.Resize((64,128)),transforms.ToTensor()])\n",
        "test_data = dsets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/courses/AI_Appl/test_data', transform=trans)\n",
        "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))\n",
        "\n",
        "with torch.no_grad():\n",
        "##### 결과 test가 이루어지는 loop\n",
        "##### 지난 source code를 그대로 사용해도 되지만, 연습삼아 직접 작성해보자"
      ],
      "metadata": {
        "id": "tnpdbiiWHY6h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}