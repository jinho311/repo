{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGmH3eHBNcUH",
        "outputId": "36ce7d0a-1c90-4f5c-8ec0-d640138ab590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 임포트 및 GPU사용, colab에 mount, 시드 부여 등 학습 모델 외적으로 사용하는 코드들\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans=transforms.Compose([transforms.Resize((320,256)),transforms.ToTensor()])\n",
        "train_data = dsets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/traing_dataset', transform=trans)\n",
        "data_loader = DataLoader(dataset = train_data, batch_size = 40,shuffle = True, num_workers=2)"
      ],
      "metadata": {
        "id": "vk3nzNEwNz6R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 Input shape=(?, 3, 320, 256)\n",
        "        #    Conv     -> (?, 32, 320, 256)\n",
        "        #    Pool     -> (?, 32, 160, 128)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 Input shape=(?, 32, 160, 128)\n",
        "        #    Conv      ->(?, 64, 160, 128)\n",
        "        #    Pool      ->(?, 64, 80, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L3 Input shape=(?, 64, 80, 64)\n",
        "        #    Conv      ->(?, 128, 80, 64)\n",
        "        #    Pool      ->(?, 128, 40, 32)\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L4 Linear 128x40x32 inputs -> 625 outputs\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(128*40*32, 625, bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=0.5))  #Dropout이란 뉴럴네트워크의 경로 몇개를 버리면서 학습하는 것으로, overfitting을 방지하는 효과를 가진다.\n",
        "        # L5 Linear 625 inputs -> 3 outputs\n",
        "        self.layer5 = torch.nn.Linear(625, 3, bias=True)\n",
        "        # 자비에르 유니폼: Linear의 초깃값을 0이아닌 자비에르방식으로 설정.\n",
        "        torch.nn.init.xavier_uniform_(self.layer5.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC , Linear연산을 하기 전에 한줄 벡터로 변환하여 입력한다.\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ZmHlBUJ6OLiH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "learning_rate = 0.0005\n",
        "training_epochs = 10"
      ],
      "metadata": {
        "id": "rjnFFqO-Pkke"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contruct model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# define cost/loss & optimizer, Multinominal 알고리즘을 사용하여 CrossEntropyLoss function을 사용하였고, SGD모델과 유사한 Adam모델을 옵티마이저로 사용하였다.\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)   \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "WleChmlbPl56"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 학습이 이루어지는 loop\n",
        "##### 지난 source code를 그대로 사용해도 되지만, 연습삼아 직접 작성해보자\n",
        "total_batch = len(data_loader)\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for num,data in enumerate(data_loader):\n",
        "        X , Y = data \n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaAhF8XfPoBV",
        "outputId": "0692a73d-6fc0-49a0-91da-076f582f6831"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning started. It takes sometime.\n",
            "[Epoch:    1] cost = 0.403838307\n",
            "[Epoch:    2] cost = 0.107941732\n",
            "[Epoch:    3] cost = 0.0539666675\n",
            "[Epoch:    4] cost = 0.0425397456\n",
            "[Epoch:    5] cost = 0.0365260132\n",
            "[Epoch:    6] cost = 0.0243192725\n",
            "[Epoch:    7] cost = 0.0211366024\n",
            "[Epoch:    8] cost = 0.0173476059\n",
            "[Epoch:    9] cost = 0.00908318534\n",
            "[Epoch:   10] cost = 0.0043152771\n",
            "Learning Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans=transforms.Compose([transforms.Resize((320,256)),transforms.ToTensor()])\n",
        "test_data = dsets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/test_dataset', transform=trans)\n",
        "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for num,data in enumerate(data_loader):\n",
        "        X , Y = data \n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "    prediction = model(X)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXIf5dquPr4K",
        "outputId": "a664f1e8-f931-4f27-acb1-535693b8e904"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f717b132050><function _MultiProcessingDataLoaderIter.__del__ at 0x7f717b132050>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "      File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "self._shutdown_workers()    \n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "self._shutdown_workers()    \n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "if w.is_alive():    \n",
            "if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}